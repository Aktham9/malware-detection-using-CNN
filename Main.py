import matplotlib.pyplot as plt
import numpy as np
import os
import PIL.Image
import tensorflow as tf
from PIL import Image
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import pathlib
import visualkeras
import random
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import plot_model
from tensorflow.keras.layers import Input, Add, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation
from tensorflow.keras.models import Model
data_dir = pathlib.Path('./Data')
total_images = 0

# Iterate over subfolders and count images
for subfolder in data_dir.iterdir():
    if subfolder.is_dir() and subfolder.name != "TEST":
        # Count images with common extensions
        image_count = len(list(subfolder.glob('*.jpg'))) + len(list(subfolder.glob('*.jpeg'))) + len(list(subfolder.glob('*.png')))
        print(f"{subfolder.name}: {image_count}")
        total_images += image_count

print("\nTotal: " + str(total_images))

# Open and display the first image from the GW directory
goodware = list(data_dir.glob('GW/*'))
if goodware:
    image = Image.open(str(goodware[0]))
    image.show()
else:
    print("No images found in GW directory.")

# Open and display the first image from the MW directory
mallware = list(data_dir.glob('MW/*'))
if mallware:
    image = Image.open(str(mallware[0]))
    image.show()
else:
    print("No images found in MW directory.")
# Set input size and prepare data for training
batch_size = 8  
img_height = 256
img_width = 256

# Prepare training dataset
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.1,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# Prepare validation dataset
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.1,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

# Print class names
class_names = train_ds.class_names
print(class_names)

# Visualize data
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
    for i in range(min(9, images.shape[0])): 
    #for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i].numpy().astype("int")])
        plt.axis("off")
plt.show()

# Check batch info
for image_batch, labels_batch in train_ds:
    print(image_batch.shape)
    print(labels_batch.shape)
    break
# Set up constants
AUTOTUNE = tf.data.AUTOTUNE

# Optimize datasets
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# Manual normalization function
def normalize(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Apply normalization to the training dataset
normalized_train_ds = train_ds.map(normalize, num_parallel_calls=AUTOTUNE)
normalized_val_ds = val_ds.map(normalize, num_parallel_calls=AUTOTUNE)

# Check normalization
image_batch, labels_batch = next(iter(normalized_train_ds))
first_image = image_batch[0]

print(np.min(first_image.numpy()), np.max(first_image.numpy()))


num_classes = len(class_names)

def residual_block(x, filters, kernel_size=3, stride=1):
    shortcut = Conv2D(filters, kernel_size=1, strides=stride, padding='same')(x)  
    shortcut = BatchNormalization()(shortcut)
    
    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)
    x = BatchNormalization()(x)
    
    x = Add()([x, shortcut])
    x = Activation('relu')(x)
    return x

input_layer = Input(shape=(img_height, img_width, 3))

# Initial Conv Layer
x = Conv2D(8, 3, padding='same', activation='relu')(input_layer)
x = BatchNormalization()(x)
x = MaxPooling2D()(x)

# Residual Blocks
x = residual_block(x, 16)
x = MaxPooling2D()(x)

x = residual_block(x, 32)
x = MaxPooling2D()(x)

x = residual_block(x, 64)
x = MaxPooling2D()(x)

x = residual_block(x, 128)
x = MaxPooling2D()(x)

x = Flatten()(x)

# Fully Connected Layers
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(128, activation='relu')(x)
x = Dense(64, activation='relu')(x)
output_layer = Dense(1, activation='sigmoid')(x)

model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
epochs = 20
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
)
#Visualize training
# Retrieve a list of accuracy and loss values
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

# Define the range of epochs
epochs_range = range(epochs)

# Plot training and validation accuracy and loss
plt.figure(figsize=(16, 8))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

# Sample a subset of images for testing
test_sample_size = 1000
gw_images = list(data_dir.glob('GW/*.jpg'))
mw_images = list(data_dir.glob('MW/*.jpg'))

random.shuffle(gw_images)
random.shuffle(mw_images)

test_gw_images = gw_images[:test_sample_size]
test_mw_images = mw_images[:test_sample_size]

test_images = test_gw_images + test_mw_images
random.shuffle(test_images)

# Prepare the results containers
resultM = [0, 0]  # [True malware, False malware]
resultG = [0, 0]  # [True goodware, False goodware]
idx = 0

# Iterate over test images
for img_name in test_images:
    whatis = "malware" if img_name in test_mw_images else "goodware"
    
    print(f"Processing image {idx}: {img_name}")
    
   # Load and preprocess the image
    img = load_img(img_name, target_size=(img_height, img_width))
    img_array = img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create a batch
    
    # Predict the class
    predictions = model.predict(img_array)
    prediction = 1 if predictions[0] >= 0.5 else 0
    
    # Map the prediction to class names
    predicted_class = class_names[prediction]
    print(f"{img_name} - Prediction: {predicted_class} -> Actual: {whatis}")
    
    # Update result counters based on prediction
    if predicted_class == "GW" and whatis == "goodware":
        resultG[0] += 1
    elif predicted_class == "GW" and whatis == "malware":
        resultG[1] += 1
    elif predicted_class == "MW" and whatis == "malware":
        resultM[0] += 1
    elif predicted_class == "MW" and whatis == "goodware":
        resultM[1] += 1
    
    idx += 1

# Print the results
print("Result for malware:", resultM)
print("Result for goodware:", resultG)

print("Total correct predictions:", resultM[0] + resultG[0])
print("Total incorrect predictions:", resultM[1] + resultG[1])

# Calculate and print the accuracy of the test process
total_predictions = resultM[0] + resultM[1] + resultG[0] + resultG[1]
correct_predictions = resultM[0] + resultG[0]
test_accuracy = correct_predictions / total_predictions
print(f"Test Accuracy: {test_accuracy:.2f}")
# Visualize the model architecture
plot_model(model, to_file="model_plot.png", show_shapes=True, show_layer_names=True)